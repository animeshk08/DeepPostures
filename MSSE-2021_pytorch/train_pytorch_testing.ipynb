{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3698696295.py:64: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3698696295.py:64: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2021 Supun Nakandala. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "if int(tensorflow.__version__.split(\".\")[0]) >= 2:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "sys.path.append('./')\n",
    "import os\n",
    "import h5py\n",
    "import pathlib\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow\n",
    "if int(tensorflow.__version__.split(\".\")[0]) >= 2:\n",
    "    import tensorflow.compat.v1 as tf\n",
    "else:\n",
    "    import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import argparse\n",
    "import json\n",
    "import pathlib\n",
    "# from tqdm import tqdm\n",
    "import sys\n",
    "# sys.path.append(pathlib.Path(__file__).parent.absolute())\n",
    "from commons import input_iterator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "os.chdir('/home/animeshkumar/workspace/adalab/workspace/DeepPostures/MSSE-2021/')\n",
    "\n",
    "from commons import cnn_bi_lstm_model, input_iterator, CNNBiLSTMModel, CNNModel\n",
    "\n",
    "# Setting random seeds\n",
    "tf.random.set_random_seed(2019)\n",
    "random.seed(2019)\n",
    "np.random.seed(2019)\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_ops(y, logits, learning_rate, n_classes, class_weights):\n",
    "    y = tf.reshape(y, [-1])\n",
    "    logits = tf.reshape(logits, [-1, n_classes])\n",
    "    balanced_accuracy, update_op = tf.metrics.mean_per_class_accuracy(y, tf.argmax(logits, 1), n_classes)\n",
    "    y = tf.reshape(tf.one_hot(y, depth=n_classes, axis=1), [-1, n_classes])\n",
    "\n",
    "    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y) * tf.reduce_sum(tf.constant(class_weights, dtype=tf.float32) * y, axis=1))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "    return train_op, update_op, balanced_accuracy, loss\n",
    "\n",
    "\n",
    "def window_generator(data_root, win_size_10s, subject_ids):\n",
    "    x_segments = []; y_segments = []\n",
    "    for subject_id in subject_ids:\n",
    "        for x_seq, _, y_seq in input_iterator(data_root, subject_id, train=True):\n",
    "            x_window = []; y_window = []\n",
    "            for x,y in zip(x_seq, y_seq):\n",
    "                x_window.append(x)\n",
    "                y_window.append(y)\n",
    "\n",
    "                if len(y_window) == win_size_10s:\n",
    "                    yield np.stack(x_window, axis=0), np.stack(y_window, axis=0)\n",
    "                    x_window = []; y_window = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Conv2dSame(torch.nn.Conv2d):\n",
    "\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ih, iw = x.size()[-2:]\n",
    "\n",
    "        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n",
    "        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np = np.random.rand(1, 1, 1, 1)\n",
    "# x = tf.constant(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:80: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_types(iterator)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_shapes(iterator)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.data.get_output_classes(iterator)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:95: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:95: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:222: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:222: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:229: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:229: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:235: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:235: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/animeshkumar/anaconda3/envs/deep_postures/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:265: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:265: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2024-05-08 13:33:50.295325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2024-05-08 13:33:52.210148: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-05-08 13:33:52.210221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (animeshkumar-msi): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:267: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 13:33:52.211529: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2024-05-08 13:33:52.245051: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "2024-05-08 13:33:52.246169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5617b94b48f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-08 13:33:52.246220: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:267: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1\n",
      "Input (672, 100, 3, 1)\n",
      "Output (672, 100, 3, 64)\n",
      "Output transposed (672, 64, 100, 3)\n",
      "Output pt (672, 64, 50, 3)\n",
      "Layer 2\n",
      "Input (672, 100, 3, 64)\n",
      "Output (672, 25, 3, 128)\n",
      "Output transposed (672, 128, 25, 3)\n",
      "Output pt (672, 128, 25, 3)\n",
      "Layer 3\n",
      "Input (672, 25, 3, 128)\n",
      "Output (672, 13, 3, 256)\n",
      "Output transposed (672, 256, 13, 3)\n",
      "Output pt (672, 256, 13, 3)\n",
      "Layer 4\n",
      "Input (672, 13, 3, 256)\n",
      "Output (672, 7, 3, 512)\n",
      "Output transposed (672, 512, 7, 3)\n",
      "Output pt (672, 512, 7, 3)\n",
      "Layer 5\n",
      "Input (672, 7, 3, 512)\n",
      "Output (672, 4, 3, 512)\n",
      "Output transposed (672, 512, 4, 3)\n",
      "Output pt (672, 512, 4, 3)\n",
      "pytorch torch.Size([672, 6144])\n",
      "(672, 6144)\n",
      "Layer 6\n",
      "Input (672, 4, 3, 512)\n",
      "Output (672, 512)\n",
      "Output pt (672, 512)\n",
      "Layer LSTM\n",
      "Input (672, 512)\n",
      "Output (96, 7, 2)\n",
      "Output pt  torch.Size([96, 7, 256])\n",
      "Output pt fc torch.Size([96, 7, 2]) tensor([[[ 0.0708, -0.0522],\n",
      "         [ 0.0714, -0.0490],\n",
      "         [ 0.0712, -0.0457],\n",
      "         ...,\n",
      "         [ 0.0700, -0.0406],\n",
      "         [ 0.0685, -0.0382],\n",
      "         [ 0.0654, -0.0353]],\n",
      "\n",
      "        [[ 0.0708, -0.0523],\n",
      "         [ 0.0713, -0.0490],\n",
      "         [ 0.0712, -0.0458],\n",
      "         ...,\n",
      "         [ 0.0700, -0.0407],\n",
      "         [ 0.0685, -0.0383],\n",
      "         [ 0.0654, -0.0353]],\n",
      "\n",
      "        [[ 0.0709, -0.0523],\n",
      "         [ 0.0714, -0.0490],\n",
      "         [ 0.0712, -0.0458],\n",
      "         ...,\n",
      "         [ 0.0700, -0.0406],\n",
      "         [ 0.0685, -0.0383],\n",
      "         [ 0.0655, -0.0353]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0702, -0.0516],\n",
      "         [ 0.0707, -0.0481],\n",
      "         [ 0.0705, -0.0447],\n",
      "         ...,\n",
      "         [ 0.0693, -0.0394],\n",
      "         [ 0.0679, -0.0370],\n",
      "         [ 0.0649, -0.0340]],\n",
      "\n",
      "        [[ 0.0702, -0.0516],\n",
      "         [ 0.0707, -0.0481],\n",
      "         [ 0.0705, -0.0447],\n",
      "         ...,\n",
      "         [ 0.0693, -0.0394],\n",
      "         [ 0.0679, -0.0371],\n",
      "         [ 0.0649, -0.0341]],\n",
      "\n",
      "        [[ 0.0702, -0.0517],\n",
      "         [ 0.0707, -0.0482],\n",
      "         [ 0.0705, -0.0447],\n",
      "         ...,\n",
      "         [ 0.0694, -0.0395],\n",
      "         [ 0.0679, -0.0371],\n",
      "         [ 0.0649, -0.0341]]], grad_fn=<ViewBackward0>)\n",
      "Loss Calculation\n",
      "y shape value [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0]]\n",
      "y shape (16, 42)\n",
      "logits shape (96, 7, 2)\n",
      "y reshape value [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "y reshape  (672,)\n",
      "logits reshape (672, 2)\n",
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:365: The name tf.metrics.mean_per_class_accuracy is deprecated. Please use tf.compat.v1.metrics.mean_per_class_accuracy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_533515/3945044641.py:365: The name tf.metrics.mean_per_class_accuracy is deprecated. Please use tf.compat.v1.metrics.mean_per_class_accuracy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y one hot [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "y reshape  (672, 2)\n",
      "Tensor(\"Sum_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Argument parser for training CNN model.')\n",
    "    optional_arguments = parser._action_groups.pop()\n",
    "    required_arguments = parser.add_argument_group('required arguments')\n",
    "    required_arguments.add_argument('--pre-processed-dir', help='Pre-processed data directory', required=False, default=\"/home/animeshkumar/workspace/adalab/workspace/DeepPostures/MSSE-2021_pytorch/preprocessed_new\")\n",
    "\n",
    "    optional_arguments.add_argument('--transfer-learning-model', help='Transfer learning model name (default: CHAP_ALL_ADULTS)', default=None, required=False, choices=['CHAP_ALL_ADULTS', 'CHAP_AUSDIAB', 'NONE'])\n",
    "    optional_arguments.add_argument('--learning-rate', help='Learning rate for training the model (default: 0.0001)', default=1e-4, type=float, required=False)\n",
    "    optional_arguments.add_argument('--num-epochs', help='Number of epochs to train the model (default: 15)', default=15, type=int, required=False)\n",
    "    optional_arguments.add_argument('--batch-size', help='Training batch size (default: 16)', default=16, type=int, required=False)\n",
    "    \n",
    "    optional_arguments.add_argument('--amp-factor', help='Factor to increase the number of neurons in the CNN layers (default: 2)', default=2, type=int, required=False)\n",
    "    optional_arguments.add_argument('--cnn-window-size', help='CNN window size in seconds on which the predictions to be made (default: 10)', default=10, type=int, required=False)\n",
    "    optional_arguments.add_argument('--bi-lstm-window-size', help='BiLSTM window size in minutes on which the predictions to be smoothed (default: 7)', default=7, type=int, required=False)\n",
    "    \n",
    "    optional_arguments.add_argument('--shuffle-buffer-size', help='Training data shuffle buffer size in terms of number of records (default: 10000)', default=10000, type=int, required=False)\n",
    "    optional_arguments.add_argument('--training-data-fraction', help='Percentage of subjects to be used for training (default: 60)', default=60, type=int, required=False)\n",
    "    optional_arguments.add_argument('--validation-data-fraction', help='Percentage of subjects to be used for validation (default: 20)', default=20, type=int, required=False)\n",
    "    optional_arguments.add_argument('--testing-data-fraction', help='Percentage of subjects to be used for testing (default: 20)', default=20, type=int, required=False)\n",
    "    optional_arguments.add_argument('--model-checkpoint-path', help='Path where the trained model will be saved (default: ./model-checkpoint)', default='./model-checkpoint', required=False)\n",
    "    \n",
    "    optional_arguments.add_argument('--num-classes', help='Number of classes in the training dataset (default: 2)', default=2, type=int, required=False)\n",
    "    optional_arguments.add_argument('--class-weights', help='Class weights for loss aggregation (default: [1.0, 1.0])', default='[1.0, 1.0]', required=False)\n",
    "    optional_arguments.add_argument('--down-sample-frequency', help='Downsample frequency in Hz for GT3X data (default: 10)', default=10, type=int, required=False)\n",
    "    optional_arguments.add_argument('--silent', help='Whether to hide info messages', default=False, required=False, action='store_true')\n",
    "    parser._action_groups.append(optional_arguments)\n",
    "    args = parser.parse_known_args()\n",
    "    args = args[0]\n",
    "    # print(args)\n",
    "\n",
    "    if os.path.exists(args.model_checkpoint_path):\n",
    "        shutil.rmtree(args.model_checkpoint_path)\n",
    "        # raise Exception('Model checkpoint: {} already exists.'.format(args.model_checkpoint_path))\n",
    "\n",
    "    if args.transfer_learning_model:\n",
    "        if args.transfer_learning_model == 'CHAP_ALL_ADULTS':\n",
    "            args.amp_factor = 2\n",
    "            args.cnn_window_size = 10\n",
    "            args.bi_lstm_window_size = 7\n",
    "        elif args.transfer_learning_model == 'CHAP_AUSDIAB':\n",
    "            args.amp_factor = 4\n",
    "            args.cnn_window_size = 10\n",
    "            args.bi_lstm_window_size = 9\n",
    "        elif args.transfer_learning_model != 'NONE':\n",
    "            raise Exception('Unsupported transfer learning model: {}'.format(args.transfer_learning_model))\n",
    "    \n",
    "    assert (args.training_data_fraction + args.validation_data_fraction + args.testing_data_fraction) == 100, 'Train, validation,test split fractions should add up to 100%'\n",
    "    \n",
    "    subject_ids = [fname.split('.')[0] for fname in os.listdir(args.pre_processed_dir)]\n",
    "    random.shuffle(subject_ids)\n",
    "\n",
    "    n_train_subjects = int(math.ceil(len(subject_ids) * args.training_data_fraction / 100.))\n",
    "    train_subjects = subject_ids[:n_train_subjects]\n",
    "    subject_ids = subject_ids[n_train_subjects:]\n",
    "\n",
    "    if (100.0 - args.training_data_fraction) > 0:\n",
    "        test_frac = args.testing_data_fraction / (100.0 - args.training_data_fraction) * 100\n",
    "    else:\n",
    "        test_frac = 0.0\n",
    "    n_test_subjects = int(math.ceil(len(subject_ids) * test_frac / 100.))\n",
    "    test_subjects = subject_ids[:n_test_subjects]\n",
    "    valid_subjects = subject_ids[n_test_subjects:]  \n",
    "\n",
    "    output_shapes = ((args.bi_lstm_window_size*(60//args.cnn_window_size), args.cnn_window_size*args.down_sample_frequency, 3), (args.bi_lstm_window_size*(60//args.cnn_window_size)))\n",
    "    bi_lstm_win_size = 60//args.down_sample_frequency * args.bi_lstm_window_size\n",
    "    train_dataset = tf.data.Dataset.from_generator(lambda: window_generator(args.pre_processed_dir, bi_lstm_win_size, train_subjects),output_types=(tf.float32, tf.int32),\n",
    "                output_shapes=output_shapes).shuffle(args.shuffle_buffer_size).batch(args.batch_size).prefetch(10)\n",
    "    if valid_subjects:\n",
    "        valid_dataset = tf.data.Dataset.from_generator(lambda: window_generator(args.pre_processed_dir, bi_lstm_win_size, valid_subjects),output_types=(tf.float32, tf.int32),\n",
    "                output_shapes=output_shapes).batch(args.batch_size).prefetch(10)\n",
    "    else:\n",
    "        valid_dataset = None\n",
    "\n",
    "    if test_subjects:\n",
    "        test_dataset = tf.data.Dataset.from_generator(lambda: window_generator(args.pre_processed_dir, bi_lstm_win_size, test_subjects),output_types=(tf.float32, tf.int32),\n",
    "                output_shapes=output_shapes).batch(args.batch_size).prefetch(10)\n",
    "    else:\n",
    "        test_dataset = None\n",
    "    \n",
    "    iterator =  tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "\n",
    "    train_init_op = iterator.make_initializer(train_dataset)\n",
    "\n",
    "    x, y = iterator.get_next()\n",
    "    \n",
    "    x = tf.reshape(x, [-1, args.cnn_window_size*args.down_sample_frequency, 3, 1])\n",
    "    x = tf.identity(x, name='input')\n",
    "    y = tf.reshape(y, [-1, bi_lstm_win_size])\n",
    "\n",
    "    class_weights = eval(args.class_weights)   \n",
    "    amp_factor = 2\n",
    "    bi_lstm_window_size  = args.bi_lstm_window_size\n",
    "    conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[3, 3],\n",
    "                                 data_format='channels_last',\n",
    "                                 padding= \"same\", use_bias=False)\n",
    "\n",
    "    def cnn_model_2(x, amp_factor=2):\n",
    "        conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[5, 3],\n",
    "                                data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1),\n",
    "                                activation=tf.nn.relu)\n",
    "        pool1 = conv1\n",
    "\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64*amp_factor, kernel_size=[5, 1],\n",
    "                                data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1),\n",
    "                                activation=tf.nn.relu)\n",
    "        pool2 = conv2\n",
    "        return pool2\n",
    "    \n",
    "    def cnn_model_3(x, amp_factor=2):\n",
    "        conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[5, 3],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool1 = conv1\n",
    "\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool2 = conv2\n",
    "\n",
    "        conv3 = tf.layers.conv2d(pool2, filters=128*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool3 = conv3\n",
    "        return pool3\n",
    "    \n",
    "    def cnn_model_4(x, amp_factor=2):\n",
    "        conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[5, 3],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool1 = conv1\n",
    "\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool2 = conv2\n",
    "\n",
    "        conv3 = tf.layers.conv2d(pool2, filters=128*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool3 = conv3\n",
    "\n",
    "        conv4 = tf.layers.conv2d(pool3, filters=256*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1), \n",
    "                                activation=tf.nn.relu)\n",
    "        pool4 = conv4\n",
    "        return pool4\n",
    "    \n",
    "    def cnn_model_5(x, amp_factor=2):\n",
    "        conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[5, 3],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool1 = conv1\n",
    "\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool2 = conv2\n",
    "\n",
    "        conv3 = tf.layers.conv2d(pool2, filters=128*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool3 = conv3\n",
    "\n",
    "        conv4 = tf.layers.conv2d(pool3, filters=256*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1), \n",
    "                                activation=tf.nn.relu)\n",
    "        pool4 = conv4\n",
    "\n",
    "        conv5 = tf.layers.conv2d(pool4, filters=256*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1), \n",
    "                                activation=tf.nn.relu)\n",
    "        pool5 = conv5\n",
    "        return pool5  \n",
    "    \n",
    "    def cnn_model_fc(x, amp_factor=2):\n",
    "        conv1 = tf.layers.conv2d(x, filters=32*amp_factor, kernel_size=[5, 3],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool1 = conv1\n",
    "\n",
    "        conv2 = tf.layers.conv2d(pool1, filters=64*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool2 = conv2\n",
    "\n",
    "        conv3 = tf.layers.conv2d(pool2, filters=128*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                 strides=(2, 1),\n",
    "                                 activation=tf.nn.relu)\n",
    "        pool3 = conv3\n",
    "\n",
    "        conv4 = tf.layers.conv2d(pool3, filters=256*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1), \n",
    "                                activation=tf.nn.relu)\n",
    "        pool4 = conv4\n",
    "\n",
    "        conv5 = tf.layers.conv2d(pool4, filters=256*amp_factor, kernel_size=[5, 1],\n",
    "                                 data_format='channels_last', padding= \"same\",\n",
    "                                strides=(2, 1), \n",
    "                                activation=tf.nn.relu)\n",
    "        pool5 = conv5        \n",
    "        pool5 = tf.transpose(pool5, [0, 3, 1, 2])\n",
    "        size = pool5.shape[-1] * pool5.shape[-2] * pool5.shape[-3]\n",
    "\n",
    "        logits = tf.layers.dense(tf.reshape(pool5,(-1, size)), units=256*amp_factor)\n",
    "        return logits\n",
    "    \n",
    "    def cnn_bi_lstm_model(x, amp_factor, bil_lstm_win_size, num_classes):\n",
    "        logits = cnn_model_fc(x, amp_factor=amp_factor)\n",
    "        logits = tf.reshape(logits, [-1, bil_lstm_win_size, 256*amp_factor])\n",
    "\n",
    "        forward_cell = tf.nn.rnn_cell.LSTMCell(128)\n",
    "        backward_cell = tf.nn.rnn_cell.LSTMCell(128)\n",
    "        encoder_outputs,_ = tf.nn.bidirectional_dynamic_rnn(\n",
    "                forward_cell,\n",
    "                backward_cell,\n",
    "                logits,\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "        encoder_outputs = tf.concat(encoder_outputs, axis=2)\n",
    "        logits = tf.layers.dense(encoder_outputs, units=num_classes)\n",
    "        logits = tf.reshape(logits, [-1, bil_lstm_win_size, num_classes])\n",
    "        return logits\n",
    "\n",
    "    cnn2 = cnn_model_2(x)\n",
    "    cnn3 = cnn_model_3(x)\n",
    "    cnn4 = cnn_model_4(x)\n",
    "    cnn5 = cnn_model_5(x)\n",
    "    cnnfc = cnn_model_fc(x)\n",
    "    num_classes = 2\n",
    "    cnn_bi_lstm = cnn_bi_lstm_model(x, amp_factor, bi_lstm_window_size, num_classes)\n",
    "\n",
    "\n",
    "   \n",
    " \n",
    "    conv1_pt = Conv2dSame(in_channels=1, out_channels=32*amp_factor, kernel_size=(5, 3), stride=(2, 1))\n",
    "    conv2_pt = Conv2dSame(in_channels=32*amp_factor, out_channels=64*amp_factor, kernel_size=(5, 1), stride=(2, 1))\n",
    "    conv3_pt = Conv2dSame(in_channels=64*amp_factor, out_channels=128*amp_factor, kernel_size=(5, 1), stride=(2, 1))\n",
    "    conv4_pt = Conv2dSame(in_channels=128*amp_factor, out_channels=256*amp_factor, kernel_size=(5, 1), stride=(2, 1))\n",
    "    conv5_pt = Conv2dSame(in_channels=256*amp_factor, out_channels=256*amp_factor, kernel_size=(5, 1), stride=(2, 1))\n",
    "    # size = \n",
    "    fc = nn.Linear(256*amp_factor * 3 * 16, 256*amp_factor)\n",
    "    py_cnn = CNNModel(amp_factor=2)\n",
    "    lstm = nn.LSTM(input_size=256*amp_factor, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "    fc_lstm = nn.Linear(128*amp_factor, 2)\n",
    "    \n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(train_init_op)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        print(\"Layer 1\")\n",
    "        print(\"Input\", np.array(x.eval()).shape)\n",
    "        output = sess.run(conv1)\n",
    "        output = np.array(output)\n",
    "        print(\"Output\", output.shape)\n",
    "        output_transposed = np.transpose(output, (0, 3, 1, 2))\n",
    "        print(\"Output transposed\", output_transposed.shape)\n",
    "\n",
    "        x_list = x.eval()\n",
    "        x_np= np.transpose(x_list, (0, 3, 1, 2)).copy()\n",
    "        x_pt = torch.tensor(x_np, dtype=torch.float32)\n",
    "        output_pt = conv1_pt(x_pt)\n",
    "        print(\"Output pt\", output_pt.detach().numpy().shape)\n",
    "\n",
    "        print(\"Layer 2\")\n",
    "        print(\"Input\", output.shape)\n",
    "        output2 = sess.run(cnn2)\n",
    "        output2 = np.array(output2)\n",
    "        print(\"Output\", output2.shape)\n",
    "        print(\"Output transposed\", np.transpose(output2, (0, 3, 1, 2)).shape)\n",
    "\n",
    "        output_pt2 = conv2_pt(output_pt)\n",
    "        print(\"Output pt\", output_pt2.detach().numpy().shape)\n",
    "\n",
    "        print(\"Layer 3\")\n",
    "        print(\"Input\", output2.shape)\n",
    "        output3 = sess.run(cnn3)\n",
    "        output3 = np.array(output3)\n",
    "        print(\"Output\", output3.shape)\n",
    "        print(\"Output transposed\", np.transpose(output3, (0, 3, 1, 2)).shape)\n",
    "\n",
    "        output_pt3 = conv3_pt(output_pt2)\n",
    "        print(\"Output pt\", output_pt3.detach().numpy().shape)\n",
    "\n",
    "        print(\"Layer 4\")\n",
    "        print(\"Input\", output3.shape)\n",
    "        output4 = sess.run(cnn4)\n",
    "        output4 = np.array(output4)\n",
    "        print(\"Output\", output4.shape)\n",
    "        print(\"Output transposed\", np.transpose(output4, (0, 3, 1, 2)).shape)\n",
    "\n",
    "        output_pt4 = conv4_pt(output_pt3)\n",
    "        print(\"Output pt\", output_pt4.detach().numpy().shape)\n",
    "\n",
    "        print(\"Layer 5\")\n",
    "        print(\"Input\", output4.shape)\n",
    "        output5 = sess.run(cnn5)\n",
    "        output5 = np.array(output5)\n",
    "        print(\"Output\", output5.shape)\n",
    "        print(\"Output transposed\", np.transpose(output5, (0, 3, 1, 2)).shape)\n",
    "\n",
    "        output_pt5 = conv5_pt(output_pt4)\n",
    "        print(\"Output pt\", output_pt5.detach().numpy().shape)\n",
    "\n",
    "        k_pt = output_pt5.view(output_pt5.size(0), -1)\n",
    "        print(\"pytorch\", k_pt.size())\n",
    "\n",
    "        pool5 = tf.transpose(output5, [0, 3, 1, 2])\n",
    "        size = pool5.shape[-1] * pool5.shape[-2] * pool5.shape[-3]\n",
    "        k = tf.reshape(pool5,(-1, size))\n",
    "        print(k.shape)\n",
    "\n",
    "        print(\"Layer 6\")\n",
    "        print(\"Input\", output5.shape)\n",
    "        outputcnn = sess.run(cnnfc)\n",
    "        outputcnn = np.array(outputcnn)\n",
    "        print(\"Output\", outputcnn.shape)\n",
    "        # print(\"Output transposed\", np.transpose(output5, (0, 3, 1, 2)).shape)\n",
    "\n",
    "        output_cnn_pt = py_cnn(x_pt)\n",
    "        print(\"Output pt\", output_cnn_pt.detach().numpy().shape)\n",
    "\n",
    "        print(\"Layer LSTM\")\n",
    "        print(\"Input\", outputcnn.shape)\n",
    "        outputlstm = sess.run(cnn_bi_lstm)\n",
    "        print(\"Output\", outputlstm.shape)\n",
    "\n",
    "        output_cnn_pt = output_cnn_pt.view(-1, bi_lstm_window_size, 256*amp_factor)\n",
    "        # print(output_cnn_pt.size())\n",
    "        outputlstm_pt = lstm(output_cnn_pt)\n",
    "        print(\"Output pt \", outputlstm_pt[0].size())\n",
    "        output_lstm_fc = fc_lstm(outputlstm_pt[0])\n",
    "        output_lstm_fc = output_lstm_fc.view(-1, bi_lstm_window_size, 2)\n",
    "        print(\"Output pt fc\", output_lstm_fc.size(), output_lstm_fc)\n",
    "\n",
    "        print(\"Loss Calculation\")\n",
    "        print(\"y shape value\", np.array(y.eval()))\n",
    "        print(\"y shape\", np.array(y.eval()).shape)\n",
    "        print(\"logits shape\", outputlstm.shape)\n",
    "        y = tf.reshape(y, [-1])\n",
    "        logits = tf.reshape(outputlstm, [-1, num_classes])\n",
    "\n",
    "        print(\"y reshape value\", np.array(y.eval()))\n",
    "        print(\"y reshape \", np.array(y.eval()).shape)\n",
    "        print(\"logits reshape\", logits.shape)\n",
    "\n",
    "        balanced_accuracy, update_op = tf.metrics.mean_per_class_accuracy(y, tf.argmax(logits, 1), num_classes)\n",
    "        y = tf.reshape(tf.one_hot(y, depth=num_classes, axis=1), [-1, num_classes])\n",
    "        print(\"y one hot\", np.array(y.eval()))\n",
    "        print(\"y reshape \", np.array(y.eval()).shape)\n",
    "\n",
    "        loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y) * tf.reduce_sum(tf.constant(class_weights, dtype=tf.float32) * y, axis=1))\n",
    "        print(loss)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # N H W C\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_postures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
